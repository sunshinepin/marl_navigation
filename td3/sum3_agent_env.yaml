# my_multi_agent_env.yaml

dl_toolbox: "torch"  # 深度学习工具箱，支持 "torch", "mindspore", "tensorlayer"
project_name: "XuanCe_Benchmark"
logger: "tensorboard"  # 日志记录工具，支持 "tensorboard", "wandb"
wandb_user_name: "xzh"
render: True
render_mode: 'rgb_array'  # 渲染模式，支持 'human', 'rgb_array'
test_mode: False
device: "cuda:0"

agent: "IPPO"  # 使用的算法，如 "IPPO", "MAPPO"
env_name: "MyNewMultiAgentEnv"
env_id: "new_env_id"
fps: 50
continuous_action: True
policy: "Gaussian_MAAC_Policy"
representation: "Basic_MLP"
vectorize: "DummyVecMultiAgentEnv"

# RNN相关设置
use_rnn: False
rnn: "GRU"
fc_hidden_sizes: [64, 64, 64]
recurrent_hidden_size: 64
N_recurrent_layers: 1
dropout: 0
normalize: "LayerNorm"
initialize: "orthogonal"
gain: 0.01

# 网络结构设置
representation_hidden_size: [64, ]
actor_hidden_size: [64, ]
critic_hidden_size: [64, ]
activation: "relu"
activation_action: "sigmoid"
use_parameter_sharing: True
use_actions_mask: False

# 强化学习超参数
seed: 1
parallels: 4  # 并行环境数量，根据你的硬件调整
buffer_size: 3200
n_epochs: 10
n_minibatch: 1
learning_rate: 0.0007
weight_decay: 0
vf_coef: 0.5
ent_coef: 0.01
target_kl: 0.25
clip_range: 0.2
gamma: 0.99

# 技巧与策略
use_linear_lr_decay: False
end_factor_lr_decay: 0.5
use_global_state: False
use_value_clip: True
value_clip_range: 0.2
use_value_norm: True
use_huber_loss: True
huber_delta: 10.0
use_advnorm: True
use_gae: True
gae_lambda: 0.95
use_grad_clip: True
grad_clip_norm: 10.0
clip_type: 1

# 训练设置
running_steps: 1000000
eval_interval: 100000
test_episode: 5

# 路径设置
log_dir: "./logs/ippo/"
model_dir: "./models/ippo/"

# 环境特定配置
launchfile: "maddpg_car3.launch"  # 替换为你的launch文件路径
environment_dim: 20
car_names: ["car1", "car2", "car3"]
car_positions: [[0, 0, 0], [1, 1, 0], [2, 2, 0]]  # 替换为实际位置
car_orientations: [0, 0, 0]  # 替换为实际角度
max_episode_steps: 500
